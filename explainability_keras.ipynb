{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "from tf_explain.core.grad_cam import GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo el modelo\n",
    "\n",
    "# Specify the path to your saved model file (.h5 or .hdf5 format)\n",
    "model_path = 'old_models/jorgenet_private_dataset/modelo_entrenado.h5'\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load the image and add it to the list of test images\n",
    "\n",
    "IMAGE_PATH = \"test_set_private/aca_61_20X.jpg\"\n",
    "imagen = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(255,255))\n",
    "x = tf.keras.preprocessing.image.img_to_array(imagen)    \n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "prediction = model.predict(x)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "data = ([imagen], None)\n",
    "explainer = GradCAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\diosdadj\\Desktop\\Master\\Lung Cancer Project\\capstone_project_UB\\explainability_keras.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diosdadj/Desktop/Master/Lung%20Cancer%20Project/capstone_project_UB/explainability_keras.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Compute GradCAM on VGG16\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/diosdadj/Desktop/Master/Lung%20Cancer%20Project/capstone_project_UB/explainability_keras.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grid \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain(data, model, class_index\u001b[39m=\u001b[39;49mtabby_cat_class_index, layer_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv2d_19\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diosdadj/Desktop/Master/Lung%20Cancer%20Project/capstone_project_UB/explainability_keras.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m explainer\u001b[39m.\u001b[39msave(grid, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgrad_cam.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tf_explain\\core\\grad_cam.py:54\u001b[0m, in \u001b[0;36mGradCAM.explain\u001b[1;34m(self, validation_data, model, class_index, layer_name, use_guided_grads, colormap, image_weight)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m layer_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     layer_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer_grad_cam_target_layer(model)\n\u001b[1;32m---> 54\u001b[0m outputs, grads \u001b[39m=\u001b[39m GradCAM\u001b[39m.\u001b[39;49mget_gradients_and_filters(\n\u001b[0;32m     55\u001b[0m     model, images, layer_name, class_index, use_guided_grads\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m cams \u001b[39m=\u001b[39m GradCAM\u001b[39m.\u001b[39mgenerate_ponderated_output(outputs, grads)\n\u001b[0;32m     60\u001b[0m heatmaps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m     61\u001b[0m     [\n\u001b[0;32m     62\u001b[0m         \u001b[39m# not showing the actual image if image_weight=0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     ]\n\u001b[0;32m     66\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tf_explain\\core\\grad_cam.py:115\u001b[0m, in \u001b[0;36mGradCAM.get_gradients_and_filters\u001b[1;34m(model, images, layer_name, class_index, use_guided_grads)\u001b[0m\n\u001b[0;32m    110\u001b[0m grad_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel(\n\u001b[0;32m    111\u001b[0m     [model\u001b[39m.\u001b[39minputs], [model\u001b[39m.\u001b[39mget_layer(layer_name)\u001b[39m.\u001b[39moutput, model\u001b[39m.\u001b[39moutput]\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 115\u001b[0m     inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcast(images, tf\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m    116\u001b[0m     tape\u001b[39m.\u001b[39mwatch(inputs)\n\u001b[0;32m    117\u001b[0m     conv_outputs, predictions \u001b[39m=\u001b[39m grad_model(inputs)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:988\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    982\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mIndexedSlices(values_cast, x\u001b[39m.\u001b[39mindices, x\u001b[39m.\u001b[39mdense_shape)\n\u001b[0;32m    983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m   \u001b[39m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[0;32m    985\u001b[0m   \u001b[39m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[0;32m    986\u001b[0m   \u001b[39m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[0;32m    987\u001b[0m   \u001b[39m# strings.\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(x, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    989\u001b[0m   \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype \u001b[39m!=\u001b[39m base_type:\n\u001b[0;32m    990\u001b[0m     x \u001b[39m=\u001b[39m gen_math_ops\u001b[39m.\u001b[39mcast(x, base_type, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1568\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:346\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    345\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 346\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    272\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    285\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    309\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\diosdadj\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute GradCAM on VGG16\n",
    "grid = explainer.explain(data, model, class_index=tabby_cat_class_index, layer_name='conv2d_19')\n",
    "explainer.save(grid, \".\", \"grad_cam.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo el modelo\n",
    "\n",
    "# Specify the path to your saved model file (.h5 or .hdf5 format)\n",
    "model_path = 'old_models/jorgenet_private_dataset/modelo_entrenado.h5'\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\diosdadj\\Desktop\\Master\\Lung Cancer Project\\capstone_project_UB\\explainability_keras.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/diosdadj/Desktop/Master/Lung%20Cancer%20Project/capstone_project_UB/explainability_keras.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m layer_index \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mfind_layer_idx(model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "layer_index = utils.find_layer_idx(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
